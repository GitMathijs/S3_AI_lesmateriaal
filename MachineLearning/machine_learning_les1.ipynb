{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning les 1 - Classificatie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook bij les 1 van de leerlijn machine learning van S3 - AI. \n",
    "\n",
    "Â© Auteur: Rianne van Os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Voor deze les is geen voorbereiding nodig.**\n",
    "\n",
    "In de machine learning leerlijn gaan we je de belangrijkste technieken leren om een voorspellend model te maken. Als je binnen de CRISP-DM cyclus de Business Understanding en Data Understanding gedaan hebt, kun je gaan nadenken over wel algoritme geschikt is om je probleem op te lossen. In deze lessenserie leer je verschillende machine learning modellen kennen, we leren je hoe je ze kunt toepassen, wat voor data preparatie stappen nodig zijn om je model te verbeteren en hoe je kunt evalueren of je model goed werkt.\n",
    "\n",
    "We starten met wat oefeningen om te ontdekken wat een machine learning model precies is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In les 3 van de data-lijn hebben we al gekeken naar de dataset van pinguinsoorten in de Palmer Archipel op Antarctica. Daar hebben we verschillende visualisaties gemaakt van de verschillende features. Nu gaan we deze dataset gebruiken om jullie eerste machine learning model te maken. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data zonder label\n",
    "\n",
    "Bij het verzamelen van de data over de pinguins was ook een stagiair-onderzoeker meegereisd naar de Palmer Archipel. Deze stagiair heeft een hoop pinguins opgemeten, maar hij bleek niet in staat om de bijbehorende soort te bepalen. De data van de stagiair kun je vinden in `pinguins_metingen_stagiair.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Opdracht 1.1\n",
    "a. Lees het bestand `pinguins_metingen_stagiair.csv' in en bekijk de metingen die de stagiair heeft gedaan.\n",
    "\n",
    "b. Maak gebruik van de dataset `pinguins.csv` om te proberen te achterhalen welke soort bij de metingen hoort. Bekijk hiervoor de beschikbare data goed. Welke features kunnen je helpen om de soort te bepalen? Kun je visualisaties maken die je hierbij helpen? Probeer je vermoeden goed te onderbouwen met behulp van cijfers of visualisaties.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../databronnen/pinguins_metingen_stagiair.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees of beslisbomen\n",
    "\n",
    "Een duidelijke, navolgbare manier om tot een keuze voor de pinguinsoort te komen, is door een beslisboom (of *decison tree*) te maken. Waarschijnlijk ken je de beslisboom nog wel uit de coronatijd, toen werd die veel gebruikt om te bepalen of je wel of niet de deur uit mocht. Je moest steeds een vraag beantwoorden, die weer leidde toe een nieuwe vraag en uiteindelijk tot het antwoord 'ja, je mag de deur uit' of 'nee, je moet thuisblijven'. \n",
    "\n",
    "Ook bij het bepalen van de pinguinsoort kun je een beslisboom maken. Hieronder een voorbeeld van een beslisboom om verschillende dieren te classificeren.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bron: https://towardsai.net/p/programming/decision-trees-explained-with-a-practical-example-fe47872d3b53\n",
    "\n",
    "![beslisboom](./../afbeeldingen/MachineLearning/simpele_beslisboom.png \"Simpele beslisboom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De rechthoeken in deze boom noemen we de *nodes* (of *knooppunten*) en de pijlen zijn de *branches* (of *takken*). De eerste node heet de root node. Daar gaat de hele dataset doorheen en deze wordt opgesplitst in een subset waarbij de dieren veren hebben, en een subset waarbij dat niet zo is. Via de branches komt de data in een nieuwe node terecht. Wordt hier weer een beslissing gemaakt, dan heet dit een *internal node* of *decision node*. Iedere decision node heeft een *splitting criterion*, zoals 'can fly?', om de subset van data die daar aankomt verder te verdelen over de volgende branches. De nodes onder aan de boom heten de *leaf nodes* en hier vind je de categorie die bij een datapunt hoort. In dit voorbeeld dus *Hawk*, *Penguin*, *Dolphin* of *Bear*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Opdracht 1.2\n",
    "Maak samen met een medestudent op papier een beslisboom om de pinguinsoort te bepalen op basis van de bekende features. In het voorbeeld hierboven worden alleen categorische variabelen meegenomen, maar voor de pinguins zul je ook gebruik moeten maken van de numerieke variabelen en kun je vragen opstellen als: 'is de flipperlengte groter dan ... mm? Je beslisboom hoeft niet correct te zijn, maar probeer een serieuze poging te doen. \n",
    "\n",
    "Gebruik je beslisboom om de soort te bepalen bij de metingen van de stagiair. Is dit hetzelfde als waar je in opdracht 1.1 op uit kwam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning\n",
    "Wat je nu gedaan hebt, is een vorm van supervised learning. Je had data waarvan je het *label* wist (in dit geval de pinguin soort), en op basis daarvan maak je een *model* (in dit geval de beslisboom), die je kan helpen om bij nieuwe data zonder label, dit label te bepalen. Dit *label* noemen we ook wel de *target* variabele.\n",
    "\n",
    "In dit voorbeeld gebruikten we dit om het werk van een fictieve klunzige stagiair te fixen, maar in de praktijk wordt dit vaak gebruikt om voorspellingen te doen. Denk bijvoorbeeld aan:\n",
    "- Fraude detectie: Kun je creditcard transacties als 'frauduleus' of 'niet frauduleus' bestempelen, op basis van transactiekenmerken zoals bedrag, locatie, tijdstip en gebruikersgeschiedenis. Hierbij kun je een model trainen op basis van transacties waarvan je weet dat ze frauduleus waren. Dit model kan je dan gebruiken om transacties af te keuren, of om bij de creditcardeigenaar na te vragen of het wel een valide transactie was. \n",
    "\n",
    "- Klantbehoud (*churn* voorspelling): Kun je bestaande klanten classificeren als 'waarschijnlijk vertrekkend' (churn) of 'waarschijnlijk blijvend', op basis van klantkenmerken zoals abonnementsduur, type contract, maandelijkse kosten, dataverbruik, aantal klantenservice interacties en demografische gegevens? Hierbij kun je een model trainen op basis van historische klantdata waarvan je weet wie er in het verleden is vertrokken en wie niet. Dit model kun je dan gebruiken om voor huidige klanten te voorspellen wie een hoog risico loopt om te vertrekken, zodat je deze klanten een aanbieding kunt geven om te blijven.\n",
    "\n",
    "- Medische diagnose: Kun je op basis van patientgegevens en testresultaten voorspellen of er vervolgonderzoek nodig is naar een bepaalde ziekte? Als je historische gegevens hebt met testresultaten en een uiteindelijke diagnose, kun je mogelijk voorspellen bij welke testresultaten er geen vervolgonderzoek meer nodig is. Dit kan veel kosten en ongemak schelen bij de patient.\n",
    "\n",
    "\n",
    "### Machine learning\n",
    "Jullie hebben het *model* voor de classificatie van pinguins net zelf gemaakt door goed naar de beschikbare data te kijken. In dit geval lukt dat aardig, maar zodra patronen in data complexer worden, zijn mensen daar niet zo goed in. Dit is precies waar *machine learning* komt kijken. Hierbij ga je niet meer zelf op zoek naar de verbanden in de data, maar besteed je dat uit aan een machine learning model. Wij gaan gebruik maken van python code, en met name van de librarie scikit-learn, om deze modellen te maken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn is een python library die allerlei functionaliteit bevat voor het trainen van machine learning modellen, datapreparatie stappen en evaluatietechnieken die daarbij horen. Zie: https://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laten we nu scikit-learn gebruiken om een beslisboom voor de pinguinsoorten te maken. Hier vind je de documentatie van de *decision tree classifier* van scikit-learn: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier In de volgende cellen demonstereren we het gebruik hiervan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Omdat sklearn een erg grote library is, is het gebruikelijk om niet de hele library te importeren, maar alleen de onderdelen die je nodig hebt. In ons geval is dat nu alleen de DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eerst maken we een decison tree object aan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om dit object een beslisboom op onze data te maken moeten we deze trainen op de dataset waar de labels bekend zijn. Deze dataset splitsen we op in een dataset met alle *feature variabelen* (de variabelen die we gebruiken om de voorspelling te maken) en een dataset met de *target variabele*, dit is de variabele die we willen gaan voorspellen. In ons geval dus de pinguinsoort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lees de pinguin dataset in\n",
    "pinguin_df = pd.read_csv('../databronnen/pinguins.csv')\n",
    "\n",
    "#Noem de dataset met features X - we gebruiken nu alleen de numerieke variabelen als features\n",
    "X = pinguin_df[['bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g']]\n",
    "#Noem de dataset met labels y\n",
    "y = pinguin_df['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens gaan we deze datasets gebruiken om het decision tree object te *trainen*. Tijdens het trainen worden de patronen in de data geleerd. In het geval van een decision tree wordt dus bepaalt op welke features de data gesplit moet worden. Dit trainen doen we door de `.fit` methode aan te roepen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu bevat het `dtc` object een getraind model. Hieronder wordt de getrainde beslisboom gevisualiseerd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dtc, feature_names=X.columns, class_names=dtc.classes_, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In de *root node* en de *decision nodes* zie je in de eerste regel het *splitting criterion*, bijvoorbeeld of de flipper lengte kleiner is dan 206.5 mm. De *branch* naar links hoort altijd bij True, en de branch naar rechts bij *False*. In de *leaf nodes* zie je welke classe erbij voorspeld wordt. Later gaan we dieper in op alle technische details van zo'n beslisboom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu we een getrainde beslisboom hebben, kunnen we deze gaan gebruiken om de pinguins waarvan de stagiair de data heeft verzameld te classificeren (oftewel de soort erbij te voorspellen). Dat kun je doen door de boom na te lopen en bij iedere beslissing de juiste tak te kiezen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Opdracht 1.3\n",
    "Bepaal handmatig door de splitsingen in de beslisboom te volgen wat de voorspelling is voor de eerste pinguin uit de dataset pinguins_metingen_stagiair.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference met sklearn\n",
    "Uiteraard is het wat omslachtig om alle voorspellingen handmatig te doen en uiteraard is hier ook een python functie voor. We kunnen op het dtc object de methode `predict` aanroepen, waarbij we de pinguin_stagiair dataset meegeven. Het is hierbij belangrijk dat deze precies dezelfde vorm heeft (dus dezelfde features) als de dataset waarop het model is getraind (in de `fit` aanroep). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Opdracht 1.4\n",
    "Maak gebruik van `dtc.predict(...)` om bij de metingen van de stagiair de soort pinguin te voorspellen. Voeg deze voorspellingen als een nieuwe kolom toe aan de dataframe `pinguins_stagiair_df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oke, nu weten we welke soorten pinguins de stagiair heeft gemeten volgens de beslisboom. Maar hoe goed zijn deze voorspellingen nou? Eigenlijk hebben we er nog geen idee van of deze classificatie ergens op slaat, want we kunnen ze niet controleren.\n",
    "\n",
    "### Train/test split\n",
    "\n",
    "Uiteraard is daar een oplossing voor bedacht, en dat is het opsplitsen van de dataset met bekende labels (in dit geval pinguin_df) in een *trainset* en een *testset*. De trainset gebruiken we om het model te maken, vervolgens gebruiken we het model om een voorspelling te maken op de testset. Omdat we daar de labels van kennen, kunnen we inschatten hoe goed de voorspellingen van het model zullen zijn op nieuwe data. In data science-terminologie zeggen we ook wel hoe goed het model *generaliseert*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Opdracht 1.5\n",
    "a. Gebruik de random-functionaliteit van numpy om de dataset pinguin_df op te splitsen in een trainset en een testset. Zorg dat de trainset uit ongeveer 70% van de data bestaat en de testset uit 30%. \n",
    "\n",
    "b. Train een nieuwe beslisboom op de trainset. \n",
    "\n",
    "c. Gebruik het getrainde model een voorspelling te maken op de testset.\n",
    "\n",
    "d. Bereken hoeveel procent van de voorspelling goed gegaan is. Als het model sommige pinguins uit de testset verkeerd geclassificeerd heeft, laat dan zien om welke rijen het gaat. Wat was de voorspelling en wat was de daadwerkelijke soort? Bepaal op basis hiervan of je vertrouwen hebt in de voorspellingen van het model op de data van de stagiair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merk op: we hebben hierboven onze eigen code geschreven voor het splitten van de dataset in een train- en een testset en we hebben zelf uitgerekend hoeveel procent van de data het juiste label heeft gekregen. Voor beiden zijn ook sklearn-functies beschikbaar, zie: \n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html.\n",
    "\n",
    "Kijk zelf in de documentatie hoe je deze functies kunt gebruiken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparatie - dummies\n",
    "Tot nu toe hebben we alleen de numerieke features meegenomen in de voorspelling, maar misschien wordt het model wel veel beter als je ook het geslacht (of het eiland) van de pinguin meeneemt. Daar kun je natuurlijk ook een *splitting criterion* van maken. We bekijken een voorbeeld waarbij we de nominale variabele `island` meenemen in het train-proces. \n",
    "\n",
    "Als we deze gewoon toevoegen tijdens het trainen krijgen we helaas een foutmelding:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_met_sex = DecisionTreeClassifier(random_state=42)\n",
    "X_train = train[['bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g', 'island']]\n",
    "y_train = train['species']\n",
    "dtc_met_sex.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien een ValueError en dit komt omdat de decision tree niet met het type 'string' om kan gaan, we zullen dus getallen moeten maken van deze kolom.\n",
    "\n",
    "Als je een ordinale variable hebt, dus een categorische variabele met een volgordelijkheid, dan is het gebruikelijk om deze om te zetten naar een numerieke variabele waarin de volgordelijkheid bewaard blijft. Bijvoorbeeld: [laag, midden, hoog] -> [1,2,3].\n",
    "\n",
    "Als er geen volgordelijkheid in zit, dan is het beter om zogenoemde `dummies` te maken. Hiervoor kun je de functie `pd.get_dummies` (zie: https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) gebruiken. Dit maakt voor iedere unieke waarde in de kolom een nieuwe kolom aan, met daarin 0 of 1. In ons geval krijgen we dus 3 nieuwe kolommen: `island_Torgerson` en `island_Biscoe` en `island_Dream`. De waarde in deze kolommen is 1 als het eiland van de pinguin overeenkomt met de naam van de kolom, anders is het 0.\n",
    "\n",
    "Merk op: eigenlijk geven 2 van de 3 kolommen al voldoende informatie. Staat er een 0 bij Torgeson en Biscoe, dan komt de pinguin automatisch van Dream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Opdracht 1.6\n",
    "\n",
    "Gebruik de `get_dummies()` functie van pandas om de kolom `island` om te zetten naar dummy variabelen. Doe dit eerst voor de trainset en train je model opnieuw. Om vervolgens te testen hoe goed je model werkt, moet je dezelfde bewerking op de testset uitvoeren. Is je model nu beter dan voorheen? Maak een plot van de beslisboom om te zien hoe de dummies gebruikt worden om de data te splitsen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance\n",
    "We hebben gezien dat de accuracy een klein beetje toeneemt als we het eiland toevoegen aan de features. Maar hoe belangrijk is die feature nou voor de voorspelling? Dan kunnen we zien met behulp van de feature_importances_ property van de decision tree. Dit geeft een lijst met de relatieve belangrijkheid van iedere feature. Hoe hoger het getal, hoe belangrijker de feature is voor de voorspelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_with_dummies.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laten we daar een dataframe van maken met de naam van de feature en de bijbehorende waarde. Deze sorteren we gelijk op de waarde van de feature importance, van hoog naar laag.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(dtc_with_dummies.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welke features zijn belangrijk voor de voorspelling van de pinguin soort en welke zouden we misschien wel weg kunnen laten bij het trainen van het model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dit voorbeeld hebben we een beslisboom gemaakt, maar er zijn veel meer machine learning modellen die je kunt gebruiken. Zowel in de sklearn library als in andere libraries. We gaan in de komende lessen nog verschillende modellen voorbij zien komen en zelf zul je, zeker in het project, ook nog nieuwe modellen gaan ontdekken. Maar als je een supervised learning probleem hebt, zul je grofweg altijd de stappen uitvoeren die we hierboven hebben gezet. Namelijk:\n",
    "\n",
    "1. Kies een modeltype (hier was dat een desision tree)\n",
    "2. Split de data in een trainset en een testset\n",
    "3. Prepareer de trainset (bijvoorbeeld door dummies te maken)\n",
    "4. Train het model op de trainset\n",
    "5. Prepareer de testset (door dezelfde stappen uit te voeren als bij de trainset)\n",
    "6. Voorspel de labels van de testset\n",
    "7. Evalueer de voorspellingen van het model\n",
    "    - Als het model goed genoeg is, gebruik het dan op nieuwe data\n",
    "    - Als het model niet goed genoeg is, probeer verbeteringen uit te voeren (bijvoorbeeld door een ander model te kiezen, of door meer data te verzamelen of betere features te kiezen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later zullen we deze stappen iets uitbreiden en zullen we dieper in gaan op het verbeteren en valideren van het model. Voor nu kun je hiermee vooruit om zelf je eerste ML-modellen te gaan trainen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificatie versus regressie\n",
    "Hier hebben we een machine learning model getraint om een categorische variabele te voorspellen. Dat noemen we een *classificatie model*. Later gaan we modellen bekijken waarmee je een continue variabele kunt voorspellen. Dat heet een *regressie model*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Opdracht 1.7\n",
    "Bekijk het volgende notebook: www.kaggle.com/nadintamer/titanic-survival-predictions-beginner\n",
    "\n",
    "Hierin worden gegevens van opvarenden van de Titanic in kaart gebracht en wordt getracht een model te maken om te voorspellen of iemand de ramp heeft overleefd of niet. Deze dataset is een veel gebruikte dataset om te oefenen met machine learning.\n",
    "\n",
    "Bekijk het notebook en beantwoord de volgende vragen:\n",
    "\n",
    "1. Over 3. Data analysis\n",
    "- Bekijk de kolommen leeftijd (Age) en cabinegegevens (Cabin). Wat is het meetniveau van beide kolommen?\n",
    "- De centrum- en spreidingsmaten worden getoond, wat is de gemiddelde leeftijd en wat is de standaarddeviatie?\n",
    "\n",
    "2. Over 4. Data visualisation\n",
    "- Onder In [7] wordt een visualisatie getoond. Welke informatie kun je halen uit deze visualisatie?\n",
    "- Stel dat je een model wilt maken dat kan voorspellen of iemand de ramp heeft overleefd op basis van persoonlijke eigenschappen. Hoe zou je een (simpel) model kunnen maken dat op basis van deze informatie goed (beter dan 70%) scoort?\n",
    "\n",
    "3. Over 4. Data visualisation\n",
    "- Onder In [8] wordt nog een visualisatie getoond. Welke informatie kun je halen uit deze visualisatie?\n",
    "- Hoe zou je een (simpel) model kunnen maken dat op basis van deze informatie? En scoort dit model beter dan bij vraag 2?\n",
    "\n",
    "4. Over 5. Cleaning Data\n",
    "- Voor de leeftijd heeft de auteur een AgeGroup gemaakt. Wat is de reden hiervoor? Wat betekent dit voor de meetniveau's / meetwaarden?\n",
    "- Hoe is de auteur omgegaan met passagiers waarvoor de leeftijd niet bekend was?\n",
    "- Hoe is de auteur omgegaan met passagiers waarvoor de cabinegegevens niet bekend waren? \n",
    "\n",
    "5. Over 6. Choosing the best model\n",
    "- Wat zijn de gebruikte features en wat is de target variabele? Wat kun je zeggen over de meetniveau's van (al) deze variabelen?\n",
    "- Een van de gebruikte modellen is een Decision Tree. De visualisatie van zo'n Decision Tree ziet er als volgt uit: https://tfbarker.files.wordpress.com/2013/12/tree.png\n",
    "- Probeer te snappen hoe deze beslisboom werkt. Wat is de voorspelling van een jongen, jonger dan 12 jaar oud die in de 2e klasse reisde?\n",
    "- Wat zegt de score van het beste model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Opdracht 1.8\n",
    "Sluit nu het kaggle notebook. Lees de dataset zelf in en maak zelf een beslisboom om de overlevingskans van de passagiers te voorspellen. Gebruik de features die je zelf wilt (begin met enkele simpele features) en probeer het model zo goed mogelijk te maken. Zorg dat je een testset apart houdt om de accuracy van je model te bepalen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-s3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
